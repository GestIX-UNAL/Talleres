
# Taller Integral de Computaci√≥n Visual

## 1. Materiales, luz y color (PBR y modelos crom√°ticos)

### üéØ Concepto

Explorar materiales PBR (albedo, roughness, metalness, normal maps) y t√©cnicas de iluminaci√≥n para crear escenas coherentes en t√©rminos de color y respuesta a la luz. Se incluyen conversiones y justificaciones crom√°ticas (RGB/HSV/CIE Lab) para selecci√≥n de paletas y contraste.

---

### ‚öôÔ∏è Funcionalidades principales

- Creaci√≥n de materiales PBR con mapas: albedo, roughness, metalness, normal.  
- Uso de HDRI para iluminaci√≥n global y luces puntuales (key, fill, rim).  
- Visualizaci√≥n de canales de color y conversi√≥n a CIELAB para an√°lisis de contraste.

---

### üß∞ Dependencias e instalaci√≥n

Depende del entorno (Three.js/Unity/Python). Ejemplo para Three.js:

```bash
npm install three @react-three/fiber @react-three/drei
```

Para pruebas en Python (inspecci√≥n de texturas):

```bash
pip install numpy opencv-python matplotlib
```

---

### ‚ñ∂Ô∏è Evidencia esperada

Coloca capturas/GIFs en `threejs/01_pbr_luz_color/evidencias/gifs/` y refi√©relas aqu√≠. Ejemplo:

![PBR resultado](threejs/01_pbr_luz_color/evidencias/gifs/01_pbr_luz_color.gif)

---

## 2. Modelado procedural desde c√≥digo

### üéØ Concepto

Generar geometr√≠a por algoritmos: rejillas, espirales, superficies param√©tricas y patrones fractales simples, controlados por par√°metros en c√≥digo para producir variaciones y animaciones.

---

### ‚öôÔ∏è Funcionalidades principales

- Generaci√≥n de mallas a partir de f√≥rmulas (param√©tricas, ruido Perlin/simplex).  
- Exportaci√≥n a OBJ/GLTF para visualizaci√≥n.  
- Animaciones por modificaci√≥n de v√©rtices en tiempo real.

---

### üß∞ Dependencias e instalaci√≥n

Para Python:

```bash
pip install numpy trimesh vedo
```

Para Three.js: librer√≠a base y utilidades (ver secci√≥n 1).

---

### ‚ñ∂Ô∏è Evidencia esperada

Guarda capturas y/o modelos en `threejs/02_procedural/evidencias/`.

![Procedural resultado](threejs/02_procedural/evidencias/gifs/demo_modelado_procedural.gif)

---

## 3. Shaders personalizados y efectos

### üéØ Concepto

Implementar shaders (GLSL/ShaderGraph) que modifiquen color y forma en funci√≥n de posici√≥n, tiempo e interacci√≥n. Incluye toon shading, noise-based deformation y efectos UV.

---

### ‚öôÔ∏è Funcionalidades principales

- Fragment y vertex shaders personalizados.  
- Par√°metros uniformes para time, mouse/gestures y textures.  
- Efectos: toon, wireframe overlay, dissolving, normal perturbation.

---

### üß∞ Dependencias e instalaci√≥n

Para proyectos web:

```bash
npm install three glslify
```

En Unity usar Shader Graph (LTS) o HLSL para shaders escritos.

---

### ‚ñ∂Ô∏è Evidencia esperada

Capturas y GIFs en `threejs/03_shaders/evidencias/`.

![Shaders resultado](threejs/03_shaders/Evidencias/gift/03_shaders.gif)

---

## 4. Texturizado din√°mico y part√≠culas

### üéØ Concepto

Materiales reactivos al tiempo y a la interacci√≥n con texturas animadas, mapas emisivos y sistemas de part√≠culas que responden a entradas (audio, gestos, par√°metros).

---

### ‚öôÔ∏è Funcionalidades principales

- Texturas animadas y mezcla de mapas (emissive, normal, offset UV).  
- Sistemas de part√≠culas sincronizados con eventos y materiales.  
- Exportaci√≥n de secuencias para evidencia.

---

### üß∞ Dependencias e instalaci√≥n

Dependencias seg√∫n entorno; ejemplos:

```bash
# Three.js
npm install three @react-three/fiber @react-three/drei

# Python (para preprocesado de texturas)
pip install numpy opencv-python
```

---

### ‚ñ∂Ô∏è Evidencia esperada

Guarda capturas/GIFs en `threejs/04_texturas_particulas/evidencias/`.

![Texturas & part√≠culas](threejs/04_texturas_particulas/Evidencias/gift/04_texturas_particulas.gif)

---

## 5. Visualizaci√≥n de im√°genes y video 360¬∞

### üéØ Concepto

Un **visor inmersivo** que permite explorar im√°genes o videos 360¬∞ dentro de una esfera virtual usando **Three.js** y **React Three Fiber**, simulando una experiencia de realidad virtual b√°sica en el navegador.

---

### ‚öôÔ∏è Funcionalidades principales

- Renderiza una **imagen HDRI panor√°mica** o un **video 360¬∞** como fondo.  
- Control de c√°mara con **OrbitControls** (rotaci√≥n libre).  
- Botones para cambiar entre modo imagen y modo video.  
- Video 360¬∞ proyectado internamente sobre una esfera invertida (`BackSide`).

---

### üß∞ Dependencias e instalaci√≥n

```bash
npm install three @react-three/fiber @react-three/drei
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

En un proyecto React con Vite o Create React App:

```bash
npm run dev
```

Coloca tus archivos multimedia en `/public`:
- `/bloem_field_sunrise_4k.hdr`  
- `/20257855-hd_1920_1080_60fps.mp4`

---

### üß† Fragmento clave

```jsx
<mesh ref={meshRef} scale={[-1, 1, 1]}>
  <sphereGeometry args={[500, 60, 40]} />
  <meshBasicMaterial side={THREE.BackSide} />
</mesh>
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 5](/2025-11-08_taller_integrado_computacion_visual/media/actividad-5/actividad_5.gif)

---

### üí° Reflexi√≥n

**Aprendizajes:** manejo de texturas HDR y videos como `VideoTexture`, control de c√°mara con OrbitControls.

**Retos t√©cnicos:** sincronizaci√≥n de texturas de video y rendimiento en navegadores.

**Mejoras posibles:** agregar puntos interactivos (hotspots), audio espacial y soporte para visores VR/WebXR.

---

## 6. Entrada e interacci√≥n (UI, input y colisiones)

### üéØ Concepto

Captura de entradas (teclado, mouse, touch) y UI para manipular escenas: sliders, botones y eventos que disparan animaciones o cambian par√°metros de materiales.

---

### ‚öôÔ∏è Funcionalidades principales

- UI HTML/Canvas o Unity UI para controles en tiempo real.  
- Detecci√≥n de colisiones/triggers para activar efectos.  
- Soporte para dispositivos t√°ctiles y gamepads.

---

### üß∞ Dependencias e instalaci√≥n

Ejemplo web:

```bash
npm install react @react-three/fiber leva
```

Ejemplo Unity: usar UI Toolkit o Canvas.

---

### ‚ñ∂Ô∏è Evidencia esperada

Capturas e instrucciones en `threejs/06_interaccion/evidencias/`.

![Interacci√≥n resultado](threejs/06_interaccion/gift/06_interaccion.gif)

---


## 7. Gestos con c√°mara web (MediaPipe Hands)

### üéØ Concepto

Un **experimento visual interactivo** basado en visi√≥n por computadora, donde el usuario puede **dibujar en el aire** usando los gestos de su mano detectados por la c√°mara. Cada gesto realiza una acci√≥n sobre el lienzo digital.

---

### ‚öôÔ∏è Funcionalidades principales

- Detecci√≥n en tiempo real de la mano con **MediaPipe Hands**.  
- Clasificaci√≥n de gestos: ‚úã `OPEN`, üëä `FIST`, ‚òùÔ∏è `POINT`, ‚úåÔ∏è `VICTORY`, üëç `THUMB_UP`, ü§è `PINCH`, üëå `OK`.  
- **Mapeo visual interactivo**:
  - `POINT`: dibujar con el √≠ndice.  
  - `PINCH`: cambiar color.  
  - `FIST`: limpiar pantalla.  
  - `OPEN`: pausar/reanudar.  
  - `THUMB_UP`: aumentar grosor del pincel.  
  - `VICTORY`: disminuir grosor.  
  - `OK`: guardar snapshot.

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python gestos_con_camara_web.py
```

- Presiona `ESC` para salir.  
- Presiona `C` para limpiar el lienzo manualmente.  

---

### üß† Fragmento clave

```python
if gesture == 'POINT' and mode_paint:
    pts_deque.append(idx_tip)
elif gesture == 'PINCH':
    color_idx = (color_idx + 1) % len(colors)
elif gesture == 'FIST':
    canvas[:] = 0
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 7](/2025-11-08_taller_integrado_computacion_visual/media/actividad-7/actividad_7.gif)

---

### üí° Reflexi√≥n

Este experimento permiti√≥ comprender la **traducci√≥n de se√±ales corporales a acciones digitales**.  
**Aprendizajes:** procesamiento de landmarks, suavizado temporal, y calibraci√≥n de umbrales de detecci√≥n.  
**Retos t√©cnicos:** la variabilidad de iluminaci√≥n y la velocidad de procesamiento en tiempo real.  
**Posibles mejoras:** detecci√≥n de m√∫ltiples manos y uso de modelos de aprendizaje profundo para reconocimiento din√°mico de gestos.

---

## 9. Interfaces multimodales (voz + gestos)

### üéØ Concepto

Extiende el experimento anterior integrando **comandos de voz (Vosk)** y **gestos simult√°neos** para crear una **interfaz multimodal** donde ambos canales (visual y auditivo) se fusionan para controlar el lienzo.

---

### ‚öôÔ∏è Funcionalidades principales

- Reconocimiento de voz **offline** con Vosk.  
- Detecci√≥n de gestos con **MediaPipe Hands**.  
- **Fusi√≥n temporal** de eventos (`voz + gesto`) para ejecutar acciones combinadas.  
- **Canvas interactivo** que responde a comandos:
  - ‚ÄúColor rojo‚Äù + gesto `PINCH` ‚Üí cambia color.  
  - ‚ÄúGuardar‚Äù + gesto `OK` ‚Üí guarda snapshot.  
  - ‚ÄúBorrar‚Äù + `FIST` ‚Üí limpia lienzo.  
  - `THUMB_UP` / `VICTORY` ‚Üí aumenta o disminuye el pincel.  

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy vosk sounddevice
```

> ‚ö†Ô∏è Descarga el modelo de voz Vosk en espa√±ol:
```bash
mkdir -p models
wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip
unzip vosk-model-small-es-0.42.zip -d models/
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python main.py
```

Requiere c√°mara y micr√≥fono activos.

---

### üß† Fragmento clave

```python
if 'color' in text:
    pinch = next((e for e in recent if e['name']=='PINCH'), None)
    if pinch:
        execute_action({'action':'set_color','color_name':chosen, 'source':'voice+pinch'})
```

---

### üì∏ Evidencia gr√°fica
![Video actividad 9](/2025-11-08_taller_integrado_computacion_visual/media/actividad-9/actividad_9.gif)

---

### üí° Reflexi√≥n

Combinar voz y gestos introduce **sinergia cognitiva** en la interacci√≥n hombre-m√°quina.  
**Aprendizajes:** uso de hilos para reconocimiento en paralelo, sincronizaci√≥n de eventos y arquitectura multimodal.  
**Retos t√©cnicos:** latencia en la sincronizaci√≥n voz-gesto y manejo concurrente del micr√≥fono y la c√°mara.  
**Mejoras futuras:** integrar un m√≥dulo de contexto para aprender patrones de interacci√≥n del usuario o comandos personalizados.
