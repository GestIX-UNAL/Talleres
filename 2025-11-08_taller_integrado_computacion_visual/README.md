
# Taller Integral de ComputaciÃ³n Visual

## ğŸŒ 5. VisualizaciÃ³n de imÃ¡genes y video 360Â°

### ğŸ¯ Concepto

Un **visor inmersivo** que permite explorar imÃ¡genes o videos 360Â° dentro de una esfera virtual usando **Three.js** y **React Three Fiber**, simulando una experiencia de realidad virtual bÃ¡sica en el navegador.

---

### âš™ï¸ Funcionalidades principales

- Renderiza una **imagen HDRI panorÃ¡mica** o un **video 360Â°** como fondo.  
- Control de cÃ¡mara con **OrbitControls** (rotaciÃ³n libre).  
- Botones para cambiar entre modo imagen y modo video.  
- Video 360Â° proyectado internamente sobre una esfera invertida (`BackSide`).

---

### ğŸ§° Dependencias e instalaciÃ³n

```bash
npm install three @react-three/fiber @react-three/drei
```

---

### â–¶ï¸ EjecuciÃ³n

En un proyecto React con Vite o Create React App:

```bash
npm run dev
```

Coloca tus archivos multimedia en `/public`:
- `/bloem_field_sunrise_4k.hdr`  
- `/20257855-hd_1920_1080_60fps.mp4`

---

### ğŸ§  Fragmento clave

```jsx
<mesh ref={meshRef} scale={[-1, 1, 1]}>
  <sphereGeometry args={[500, 60, 40]} />
  <meshBasicMaterial side={THREE.BackSide} />
</mesh>
```

---

### ğŸ“¸ Evidencia grÃ¡fica (sugerida)

![Video actividad 5](/media/actividad-5/actividad_5.gif)

---

### ğŸ’¡ ReflexiÃ³n

**Aprendizajes:** manejo de texturas HDR y videos como `VideoTexture`, control de cÃ¡mara con OrbitControls.

**Retos tÃ©cnicos:** sincronizaciÃ³n de texturas de video y rendimiento en navegadores.

**Mejoras posibles:** agregar puntos interactivos (hotspots), audio espacial y soporte para visores VR/WebXR.

---


## 7. Gestos con cÃ¡mara web (MediaPipe Hands)

### ğŸ¯ Concepto

Un **experimento visual interactivo** basado en visiÃ³n por computadora, donde el usuario puede **dibujar en el aire** usando los gestos de su mano detectados por la cÃ¡mara. Cada gesto realiza una acciÃ³n sobre el lienzo digital.

---

### âš™ï¸ Funcionalidades principales

- DetecciÃ³n en tiempo real de la mano con **MediaPipe Hands**.  
- ClasificaciÃ³n de gestos: âœ‹ `OPEN`, ğŸ‘Š `FIST`, â˜ï¸ `POINT`, âœŒï¸ `VICTORY`, ğŸ‘ `THUMB_UP`, ğŸ¤ `PINCH`, ğŸ‘Œ `OK`.  
- **Mapeo visual interactivo**:
  - `POINT`: dibujar con el Ã­ndice.  
  - `PINCH`: cambiar color.  
  - `FIST`: limpiar pantalla.  
  - `OPEN`: pausar/reanudar.  
  - `THUMB_UP`: aumentar grosor del pincel.  
  - `VICTORY`: disminuir grosor.  
  - `OK`: guardar snapshot.

---

### ğŸ§° Dependencias e instalaciÃ³n

```bash
pip install opencv-python mediapipe numpy
```

---

### â–¶ï¸ EjecuciÃ³n

```bash
python gestos_con_camara_web.py
```

- Presiona `ESC` para salir.  
- Presiona `C` para limpiar el lienzo manualmente.  

---

### ğŸ§  Fragmento clave

```python
if gesture == 'POINT' and mode_paint:
    pts_deque.append(idx_tip)
elif gesture == 'PINCH':
    color_idx = (color_idx + 1) % len(colors)
elif gesture == 'FIST':
    canvas[:] = 0
```

---

### ğŸ“¸ Evidencia grÃ¡fica (sugerida)

![Video actividad 7](/media/actividad-7/actividad_7.gif)

---

### ğŸ’¡ ReflexiÃ³n

Este experimento permitiÃ³ comprender la **traducciÃ³n de seÃ±ales corporales a acciones digitales**.  
**Aprendizajes:** procesamiento de landmarks, suavizado temporal, y calibraciÃ³n de umbrales de detecciÃ³n.  
**Retos tÃ©cnicos:** la variabilidad de iluminaciÃ³n y la velocidad de procesamiento en tiempo real.  
**Posibles mejoras:** detecciÃ³n de mÃºltiples manos y uso de modelos de aprendizaje profundo para reconocimiento dinÃ¡mico de gestos.

---

## 9. Interfaces multimodales (voz + gestos)

### ğŸ¯ Concepto

Extiende el experimento anterior integrando **comandos de voz (Vosk)** y **gestos simultÃ¡neos** para crear una **interfaz multimodal** donde ambos canales (visual y auditivo) se fusionan para controlar el lienzo.

---

### âš™ï¸ Funcionalidades principales

- Reconocimiento de voz **offline** con Vosk.  
- DetecciÃ³n de gestos con **MediaPipe Hands**.  
- **FusiÃ³n temporal** de eventos (`voz + gesto`) para ejecutar acciones combinadas.  
- **Canvas interactivo** que responde a comandos:
  - â€œColor rojoâ€ + gesto `PINCH` â†’ cambia color.  
  - â€œGuardarâ€ + gesto `OK` â†’ guarda snapshot.  
  - â€œBorrarâ€ + `FIST` â†’ limpia lienzo.  
  - `THUMB_UP` / `VICTORY` â†’ aumenta o disminuye el pincel.  

---

### ğŸ§° Dependencias e instalaciÃ³n

```bash
pip install opencv-python mediapipe numpy vosk sounddevice
```

> âš ï¸ Descarga el modelo de voz Vosk en espaÃ±ol:
```bash
mkdir -p models
wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip
unzip vosk-model-small-es-0.42.zip -d models/
```

---

### â–¶ï¸ EjecuciÃ³n

```bash
python main.py
```

Requiere cÃ¡mara y micrÃ³fono activos.

---

### ğŸ§  Fragmento clave

```python
if 'color' in text:
    pinch = next((e for e in recent if e['name']=='PINCH'), None)
    if pinch:
        execute_action({'action':'set_color','color_name':chosen, 'source':'voice+pinch'})
```

---

### ğŸ“¸ Evidencia grÃ¡fica (sugerida)

![Video actividad 9](/media/actividad-9/actividad_9.gif)

---

### ğŸ’¡ ReflexiÃ³n

Combinar voz y gestos introduce **sinergia cognitiva** en la interacciÃ³n hombre-mÃ¡quina.  
**Aprendizajes:** uso de hilos para reconocimiento en paralelo, sincronizaciÃ³n de eventos y arquitectura multimodal.  
**Retos tÃ©cnicos:** latencia en la sincronizaciÃ³n voz-gesto y manejo concurrente del micrÃ³fono y la cÃ¡mara.  
**Mejoras futuras:** integrar un mÃ³dulo de contexto para aprender patrones de interacciÃ³n del usuario o comandos personalizados.