
# Taller Integral de Computaci√≥n Visual

## 5. Visualizaci√≥n de im√°genes y video 360¬∞

### üéØ Concepto

Un **visor inmersivo** que permite explorar im√°genes o videos 360¬∞ dentro de una esfera virtual usando **Three.js** y **React Three Fiber**, simulando una experiencia de realidad virtual b√°sica en el navegador.

---

### ‚öôÔ∏è Funcionalidades principales

- Renderiza una **imagen HDRI panor√°mica** o un **video 360¬∞** como fondo.  
- Control de c√°mara con **OrbitControls** (rotaci√≥n libre).  
- Botones para cambiar entre modo imagen y modo video.  
- Video 360¬∞ proyectado internamente sobre una esfera invertida (`BackSide`).

---

### üß∞ Dependencias e instalaci√≥n

```bash
npm install three @react-three/fiber @react-three/drei
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

En un proyecto React con Vite o Create React App:

```bash
npm run dev
```

Coloca tus archivos multimedia en `/public`:
- `/bloem_field_sunrise_4k.hdr`  
- `/20257855-hd_1920_1080_60fps.mp4`

---

### üß† Fragmento clave

```jsx
<mesh ref={meshRef} scale={[-1, 1, 1]}>
  <sphereGeometry args={[500, 60, 40]} />
  <meshBasicMaterial side={THREE.BackSide} />
</mesh>
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 5](/2025-11-08_taller_integrado_computacion_visual/media/actividad-5/actividad_5.gif)

---

### üí° Reflexi√≥n

**Aprendizajes:** manejo de texturas HDR y videos como `VideoTexture`, control de c√°mara con OrbitControls.

**Retos t√©cnicos:** sincronizaci√≥n de texturas de video y rendimiento en navegadores.

**Mejoras posibles:** agregar puntos interactivos (hotspots), audio espacial y soporte para visores VR/WebXR.

---


## 7. Gestos con c√°mara web (MediaPipe Hands)

### üéØ Concepto

Un **experimento visual interactivo** basado en visi√≥n por computadora, donde el usuario puede **dibujar en el aire** usando los gestos de su mano detectados por la c√°mara. Cada gesto realiza una acci√≥n sobre el lienzo digital.

---

### ‚öôÔ∏è Funcionalidades principales

- Detecci√≥n en tiempo real de la mano con **MediaPipe Hands**.  
- Clasificaci√≥n de gestos: ‚úã `OPEN`, üëä `FIST`, ‚òùÔ∏è `POINT`, ‚úåÔ∏è `VICTORY`, üëç `THUMB_UP`, ü§è `PINCH`, üëå `OK`.  
- **Mapeo visual interactivo**:
  - `POINT`: dibujar con el √≠ndice.  
  - `PINCH`: cambiar color.  
  - `FIST`: limpiar pantalla.  
  - `OPEN`: pausar/reanudar.  
  - `THUMB_UP`: aumentar grosor del pincel.  
  - `VICTORY`: disminuir grosor.  
  - `OK`: guardar snapshot.

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python gestos_con_camara_web.py
```

- Presiona `ESC` para salir.  
- Presiona `C` para limpiar el lienzo manualmente.  

---

### üß† Fragmento clave

```python
if gesture == 'POINT' and mode_paint:
    pts_deque.append(idx_tip)
elif gesture == 'PINCH':
    color_idx = (color_idx + 1) % len(colors)
elif gesture == 'FIST':
    canvas[:] = 0
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 7](/2025-11-08_taller_integrado_computacion_visual/media/actividad-7/actividad_7.gif)

---

### üí° Reflexi√≥n

Este experimento permiti√≥ comprender la **traducci√≥n de se√±ales corporales a acciones digitales**.  
**Aprendizajes:** procesamiento de landmarks, suavizado temporal, y calibraci√≥n de umbrales de detecci√≥n.  
**Retos t√©cnicos:** la variabilidad de iluminaci√≥n y la velocidad de procesamiento en tiempo real.  
**Posibles mejoras:** detecci√≥n de m√∫ltiples manos y uso de modelos de aprendizaje profundo para reconocimiento din√°mico de gestos.

---

## 9. Interfaces multimodales (voz + gestos)

### üéØ Concepto

Extiende el experimento anterior integrando **comandos de voz (Vosk)** y **gestos simult√°neos** para crear una **interfaz multimodal** donde ambos canales (visual y auditivo) se fusionan para controlar el lienzo.

---

### ‚öôÔ∏è Funcionalidades principales

- Reconocimiento de voz **offline** con Vosk.  
- Detecci√≥n de gestos con **MediaPipe Hands**.  
- **Fusi√≥n temporal** de eventos (`voz + gesto`) para ejecutar acciones combinadas.  
- **Canvas interactivo** que responde a comandos:
  - ‚ÄúColor rojo‚Äù + gesto `PINCH` ‚Üí cambia color.  
  - ‚ÄúGuardar‚Äù + gesto `OK` ‚Üí guarda snapshot.  
  - ‚ÄúBorrar‚Äù + `FIST` ‚Üí limpia lienzo.  
  - `THUMB_UP` / `VICTORY` ‚Üí aumenta o disminuye el pincel.  

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy vosk sounddevice
```

> ‚ö†Ô∏è Descarga el modelo de voz Vosk en espa√±ol:
```bash
mkdir -p models
wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip
unzip vosk-model-small-es-0.42.zip -d models/
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python main.py
```

Requiere c√°mara y micr√≥fono activos.

---

### üß† Fragmento clave

```python
if 'color' in text:
    pinch = next((e for e in recent if e['name']=='PINCH'), None)
    if pinch:
        execute_action({'action':'set_color','color_name':chosen, 'source':'voice+pinch'})
```

---

### üì∏ Evidencia gr√°fica
![Video actividad 9](/2025-11-08_taller_integrado_computacion_visual/media/actividad-9/actividad_9.gif)

---

### üí° Reflexi√≥n

Combinar voz y gestos introduce **sinergia cognitiva** en la interacci√≥n hombre-m√°quina.  
**Aprendizajes:** uso de hilos para reconocimiento en paralelo, sincronizaci√≥n de eventos y arquitectura multimodal.  
**Retos t√©cnicos:** latencia en la sincronizaci√≥n voz-gesto y manejo concurrente del micr√≥fono y la c√°mara.  
**Mejoras futuras:** integrar un m√≥dulo de contexto para aprender patrones de interacci√≥n del usuario o comandos personalizados.
