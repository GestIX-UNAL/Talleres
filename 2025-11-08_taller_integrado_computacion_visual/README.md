
# Taller Integral de Computaci√≥n Visual

## 1. Materiales, luz y color (PBR y modelos crom√°ticos)

### üéØ Concepto

Explorar materiales PBR (albedo, roughness, metalness, normal maps) y t√©cnicas de iluminaci√≥n para crear escenas coherentes en t√©rminos de color y respuesta a la luz. Se incluyen conversiones y justificaciones crom√°ticas (RGB/HSV/CIE Lab) para selecci√≥n de paletas y contraste.

---

### ‚öôÔ∏è Funcionalidades principales

- Creaci√≥n de materiales PBR con mapas: albedo, roughness, metalness, normal.  
- Uso de HDRI para iluminaci√≥n global y luces puntuales (key, fill, rim).  
- Visualizaci√≥n de canales de color y conversi√≥n a CIELAB para an√°lisis de contraste.

---

### üß∞ Dependencias e instalaci√≥n

Depende del entorno (Three.js/Unity/Python). Ejemplo para Three.js:

```bash
npm install three @react-three/fiber @react-three/drei
```

Para pruebas en Python (inspecci√≥n de texturas):

```bash
pip install numpy opencv-python matplotlib
```

---

### ‚ñ∂Ô∏è Evidencia esperada

Coloca capturas/GIFs en `threejs/01_pbr_luz_color/evidencias/gifs/` y refi√©relas aqu√≠. Ejemplo:

![PBR resultado](threejs/01_pbr_luz_color/evidencias/gifs/01_pbr_luz_color.gif)

---

## 2. Modelado procedural desde c√≥digo

### üéØ Concepto

Generar geometr√≠a por algoritmos: rejillas, espirales, superficies param√©tricas y patrones fractales simples, controlados por par√°metros en c√≥digo para producir variaciones y animaciones.

---

### ‚öôÔ∏è Funcionalidades principales

- Generaci√≥n de mallas a partir de f√≥rmulas (param√©tricas, ruido Perlin/simplex).  
- Exportaci√≥n a OBJ/GLTF para visualizaci√≥n.  
- Animaciones por modificaci√≥n de v√©rtices en tiempo real.

---

### üß∞ Dependencias e instalaci√≥n

Para Python:

```bash
pip install numpy trimesh vedo
```

Para Three.js: librer√≠a base y utilidades (ver secci√≥n 1).

---

### ‚ñ∂Ô∏è Evidencia esperada

Guarda capturas y/o modelos en `threejs/02_procedural/evidencias/`.

![Procedural resultado](threejs/02_procedural/evidencias/gifs/demo_modelado_procedural.gif)

---

## 3. Shaders personalizados y efectos

### üéØ Concepto

Implementar shaders (GLSL/ShaderGraph) que modifiquen color y forma en funci√≥n de posici√≥n, tiempo e interacci√≥n. Incluye toon shading, noise-based deformation y efectos UV.

---

### ‚öôÔ∏è Funcionalidades principales

- Fragment y vertex shaders personalizados.  
- Par√°metros uniformes para time, mouse/gestures y textures.  
- Efectos: toon, wireframe overlay, dissolving, normal perturbation.

---

### üß∞ Dependencias e instalaci√≥n

Para proyectos web:

```bash
npm install three glslify
```

En Unity usar Shader Graph (LTS) o HLSL para shaders escritos.

---

### ‚ñ∂Ô∏è Evidencia esperada

Capturas y GIFs en `threejs/03_shaders/evidencias/`.

![Shaders resultado](threejs/03_shaders/Evidencias/gift/03_shaders.gif)

---

## 4. Texturizado din√°mico y part√≠culas

### üéØ Concepto

Materiales reactivos al tiempo y a la interacci√≥n con texturas animadas, mapas emisivos y sistemas de part√≠culas que responden a entradas (audio, gestos, par√°metros).

---

### ‚öôÔ∏è Funcionalidades principales

- Texturas animadas y mezcla de mapas (emissive, normal, offset UV).  
- Sistemas de part√≠culas sincronizados con eventos y materiales.  
- Exportaci√≥n de secuencias para evidencia.

---

### üß∞ Dependencias e instalaci√≥n

Dependencias seg√∫n entorno; ejemplos:

```bash
# Three.js
npm install three @react-three/fiber @react-three/drei

# Python (para preprocesado de texturas)
pip install numpy opencv-python
```

---

### ‚ñ∂Ô∏è Evidencia esperada

Guarda capturas/GIFs en `threejs/04_texturas_particulas/evidencias/`.

![Texturas & part√≠culas](threejs/04_texturas_particulas/Evidencias/gift/04_texturas_particulas.gif)

---

## 5. Visualizaci√≥n de im√°genes y video 360¬∞

### üéØ Concepto

Un **visor inmersivo** que permite explorar im√°genes o videos 360¬∞ dentro de una esfera virtual usando **Three.js** y **React Three Fiber**, simulando una experiencia de realidad virtual b√°sica en el navegador.

---

### ‚öôÔ∏è Funcionalidades principales

- Renderiza una **imagen HDRI panor√°mica** o un **video 360¬∞** como fondo.  
- Control de c√°mara con **OrbitControls** (rotaci√≥n libre).  
- Botones para cambiar entre modo imagen y modo video.  
- Video 360¬∞ proyectado internamente sobre una esfera invertida (`BackSide`).

---

### üß∞ Dependencias e instalaci√≥n

```bash
npm install three @react-three/fiber @react-three/drei
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

En un proyecto React con Vite o Create React App:

```bash
npm run dev
```

Coloca tus archivos multimedia en `/public`:
- `/bloem_field_sunrise_4k.hdr`  
- `/20257855-hd_1920_1080_60fps.mp4`

---

### üß† Fragmento clave

```jsx
<mesh ref={meshRef} scale={[-1, 1, 1]}>
  <sphereGeometry args={[500, 60, 40]} />
  <meshBasicMaterial side={THREE.BackSide} />
</mesh>
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 5](/2025-11-08_taller_integrado_computacion_visual/media/actividad-5/actividad_5.gif)

---

### üí° Reflexi√≥n

**Aprendizajes:** manejo de texturas HDR y videos como `VideoTexture`, control de c√°mara con OrbitControls.

**Retos t√©cnicos:** sincronizaci√≥n de texturas de video y rendimiento en navegadores.

**Mejoras posibles:** agregar puntos interactivos (hotspots), audio espacial y soporte para visores VR/WebXR.

---

## 6. Entrada e interacci√≥n (UI, input y colisiones)

### üéØ Concepto

Captura de entradas (teclado, mouse, touch) y UI para manipular escenas: sliders, botones y eventos que disparan animaciones o cambian par√°metros de materiales.

---

### ‚öôÔ∏è Funcionalidades principales

- UI HTML/Canvas o Unity UI para controles en tiempo real.  
- Detecci√≥n de colisiones/triggers para activar efectos.  
- Soporte para dispositivos t√°ctiles y gamepads.

---

### üß∞ Dependencias e instalaci√≥n

Ejemplo web:

```bash
npm install react @react-three/fiber leva
```

Ejemplo Unity: usar UI Toolkit o Canvas.

---

### ‚ñ∂Ô∏è Evidencia esperada

Capturas e instrucciones en `threejs/06_interaccion/evidencias/`.

![Interacci√≥n resultado](threejs/06_interaccion/gift/06_interaccion.gif)

---


## 7. Gestos con c√°mara web (MediaPipe Hands)

### üéØ Concepto

Un **experimento visual interactivo** basado en visi√≥n por computadora, donde el usuario puede **dibujar en el aire** usando los gestos de su mano detectados por la c√°mara. Cada gesto realiza una acci√≥n sobre el lienzo digital.

---

### ‚öôÔ∏è Funcionalidades principales

- Detecci√≥n en tiempo real de la mano con **MediaPipe Hands**.  
- Clasificaci√≥n de gestos: ‚úã `OPEN`, üëä `FIST`, ‚òùÔ∏è `POINT`, ‚úåÔ∏è `VICTORY`, üëç `THUMB_UP`, ü§è `PINCH`, üëå `OK`.  
- **Mapeo visual interactivo**:
  - `POINT`: dibujar con el √≠ndice.  
  - `PINCH`: cambiar color.  
  - `FIST`: limpiar pantalla.  
  - `OPEN`: pausar/reanudar.  
  - `THUMB_UP`: aumentar grosor del pincel.  
  - `VICTORY`: disminuir grosor.  
  - `OK`: guardar snapshot.

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python gestos_con_camara_web.py
```

- Presiona `ESC` para salir.  
- Presiona `C` para limpiar el lienzo manualmente.  

---

### üß† Fragmento clave

```python
if gesture == 'POINT' and mode_paint:
    pts_deque.append(idx_tip)
elif gesture == 'PINCH':
    color_idx = (color_idx + 1) % len(colors)
elif gesture == 'FIST':
    canvas[:] = 0
```

---

### üì∏ Evidencia gr√°fica

![Video actividad 7](/2025-11-08_taller_integrado_computacion_visual/media/actividad-7/actividad_7.gif)

---

### üí° Reflexi√≥n

Este experimento permiti√≥ comprender la **traducci√≥n de se√±ales corporales a acciones digitales**.  
**Aprendizajes:** procesamiento de landmarks, suavizado temporal, y calibraci√≥n de umbrales de detecci√≥n.  
**Retos t√©cnicos:** la variabilidad de iluminaci√≥n y la velocidad de procesamiento en tiempo real.  
**Posibles mejoras:** detecci√≥n de m√∫ltiples manos y uso de modelos de aprendizaje profundo para reconocimiento din√°mico de gestos.

---
## 8. Reconocimiento de voz y control por comandos

### üß∞ Dependencias e instalaci√≥n
```bash
pip install SpeechRecognition pyaudio pyttsx3 pygame numpy
```
---
### ‚ñ∂Ô∏è Ejecuci√≥n
```bash
python voice_control.py
```
Aseg√∫rate de tener un micr√≥fono conectado y configurado correctamente.
---
### üß† Fragmento clave
```python
def asr_worker():
    while True:
        audio = audio_q.get()
        try:
            # Online (simple y robusto). Si requieres offline, cambia a recognize_sphinx(language="es-ES")
            text = r.recognize_google(audio, language=LANG).lower().strip()
            print("Heard:", text)
            executed = False
            for key, (op, val) in COMMANDS.items():
                if key in text:
                    state.apply(op, val)
                    say(key)
                    executed = True
            if not executed:
                say("No entendido")
        except Exception as e:
            print("ASR error:", e)
```
---

### üí° Reflexi√≥n

La implementaci√≥n de reconocimiento de voz permite una interacci√≥n m√°s natural y fluida con el sistema.  
**Aprendizajes:** integraci√≥n de bibliotecas de reconocimiento de voz, manejo de excepciones y control visual mediante comandos de voz.  
**Retos t√©cnicos:** variabilidad en la calidad del audio y la precisi√≥n del reconocimiento.  
**Mejoras posibles:** agregar soporte para m√∫ltiples idiomas y comandos personalizados.

---

### Evidencia gr√°fica
![Video actividad 8](media/actividad-8/actividad_8.gif)

---
## 9. Interfaces multimodales (voz + gestos)

### üéØ Concepto

Extiende el experimento anterior integrando **comandos de voz (Vosk)** y **gestos simult√°neos** para crear una **interfaz multimodal** donde ambos canales (visual y auditivo) se fusionan para controlar el lienzo.

---

### ‚öôÔ∏è Funcionalidades principales

- Reconocimiento de voz **offline** con Vosk.  
- Detecci√≥n de gestos con **MediaPipe Hands**.  
- **Fusi√≥n temporal** de eventos (`voz + gesto`) para ejecutar acciones combinadas.  
- **Canvas interactivo** que responde a comandos:
  - ‚ÄúColor rojo‚Äù + gesto `PINCH` ‚Üí cambia color.  
  - ‚ÄúGuardar‚Äù + gesto `OK` ‚Üí guarda snapshot.  
  - ‚ÄúBorrar‚Äù + `FIST` ‚Üí limpia lienzo.  
  - `THUMB_UP` / `VICTORY` ‚Üí aumenta o disminuye el pincel.  

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install opencv-python mediapipe numpy vosk sounddevice
```

> ‚ö†Ô∏è Descarga el modelo de voz Vosk en espa√±ol:
```bash
mkdir -p models
wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip
unzip vosk-model-small-es-0.42.zip -d models/
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python main.py
```

Requiere c√°mara y micr√≥fono activos.

---

### üß† Fragmento clave

```python
if 'color' in text:
    pinch = next((e for e in recent if e['name']=='PINCH'), None)
    if pinch:
        execute_action({'action':'set_color','color_name':chosen, 'source':'voice+pinch'})
```

---

### üì∏ Evidencia gr√°fica
![Video actividad 9](/2025-11-08_taller_integrado_computacion_visual/media/actividad-9/actividad_9.gif)

---

### üí° Reflexi√≥n

Combinar voz y gestos introduce **sinergia cognitiva** en la interacci√≥n hombre-m√°quina.  
**Aprendizajes:** uso de hilos para reconocimiento en paralelo, sincronizaci√≥n de eventos y arquitectura multimodal.  
**Retos t√©cnicos:** latencia en la sincronizaci√≥n voz-gesto y manejo concurrente del micr√≥fono y la c√°mara.  
**Mejoras futuras:** integrar un m√≥dulo de contexto para aprender patrones de interacci√≥n del usuario o comandos personalizados.

---

## 10. Simulaci√≥n BCI (EEG sint√©tico y control)

### üéØ Concepto

Simulaci√≥n de se√±ales EEG sint√©ticas que permiten explorar patrones de actividad cerebral y su relaci√≥n con el control visual.

---

### üß∞ Dependencias e instalaci√≥n

```bash
pip install -r requirements.txt
```
---

```bash
pip install numpy scipy pygame
```

---

### ‚ñ∂Ô∏è Ejecuci√≥n

```bash
python eeg_sim.py
```

Aseg√∫rate de tener los permisos necesarios para acceder a los dispositivos de entrada si es necesario.

---

### üß† Fragmento clave

```python
# -*- coding: utf-8 -*-
import numpy as np
from scipy.signal import butter, lfilter, welch
import pygame, random

# -------- Config EEG --------
FS = 256                   # Hz
WIN = 2.5                  # s por ventana
N  = int(FS*WIN)
ALPHA = (8,12)
BETA  = (13,30)
TH_ALPHA = 2.2             # umbral relativo simple
TH_BETA  = 2.0

# -------- S√≠ntesis ----------
def synth_eeg(n, fs, a_amp=1.0, b_amp=0.8, noise=0.4):
  t = np.arange(n)/fs
  alpha = a_amp*np.sin(2*np.pi*10*t + np.random.rand()*2*np.pi)
  beta  = b_amp*np.sin(2*np.pi*20*t + np.random.rand()*2*np.pi)
  pink  = noise*np.cumsum(np.random.randn(n)); pink /= np.max(np.abs(pink)+1e-6)
  return alpha + beta + 0.4*pink

# ... (resto del c√≥digo)
```

---

### üí° Reflexi√≥n

La simulaci√≥n de EEG permite explorar patrones de actividad cerebral y su relaci√≥n con el control de dispositivos.  
**Aprendizajes:** generaci√≥n de se√±ales sint√©ticas y visualizaci√≥n de datos en tiempo real.  
**Retos t√©cnicos:** modelar adecuadamente la variabilidad de las se√±ales EEG reales.  
**Mejoras posibles:** integrar datos reales de EEG y aplicar t√©cnicas de procesamiento de se√±ales para an√°lisis m√°s profundos.

---

### Evidencia gr√°fica
![Video actividad 10](media/actividad-10/actividad_10.gif)

---

## 11. Espacios proyectivos y matrices de proyecci√≥n
### üéØ Concepto
Simulaci√≥n de proyecciones en 3D utilizando c√°maras perspectiva y ortogr√°fica para visualizar la diferencia entre ambas.

---
### ‚öôÔ∏è Funcionalidades principales
- Alternar entre c√°mara perspectiva y ortogr√°fica con la tecla `[C]`.  
- Activar/desactivar el mapa de profundidad con la tecla `[D]`.  
- Visualizaci√≥n de un objeto 3D (Torus Knot) en un entorno iluminado.

---
### ‚ñ∂Ô∏è Ejecuci√≥n
Abre el archivo HTML en un navegador compatible con WebGL.

---
### üß† Fragmento clave
```javascript
const persp = new THREE.PerspectiveCamera(60, innerWidth / innerHeight, 0.1, 100);
const ortho = new THREE.OrthographicCamera(-orthoH * innerWidth / innerHeight, orthoH * innerWidth / innerHeight, orthoH, -orthoH, 0.1, 100);
```
---
### üí° Reflexi√≥n
La comparaci√≥n entre proyecciones perspectiva y ortogr√°fica permite entender c√≥mo afectan la percepci√≥n de la profundidad y la escala en entornos 3D.  
**Aprendizajes:** manejo de diferentes tipos de c√°maras en Three.js y su impacto visual.  
**Retos t√©cnicos:** optimizaci√≥n del rendimiento al alternar entre c√°maras.  
**Mejoras posibles:** agregar m√°s geometr√≠as y efectos visuales para enriquecer la experiencia.

---

### üì∏ Evidencia gr√°fica

![Video actividad 11](media/actividad-11/actividad_11.gif)
